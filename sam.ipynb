{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain tiktoken google-generativeai langchain-google-genai\n",
    "%pip install git+https://github.com/huggingface/transformers -q\n",
    "%pip install torch\n",
    "%pip install kenlm pyctcdecode\n",
    "%pip install ffmpeg-python ffmpeg\n",
    "%pip install googletrans\n",
    "%pip install --upgrade googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio='rec\\Recording (9).mp3'      #THE RECORDED audio file from the browser goes here or there is another option, do whichever is easy for you\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "display(Audio(audio, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline                              #The speech to text model \n",
    "\n",
    "ai4bharat = pipeline(\"automatic-speech-recognition\", model=\"ai4bharat/indicwav2vec-hindi\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_fin = ai4bharat(audio)         #If saving the audio is tough, you can directly use the audio file from the browser here if possible\n",
    "text1 =text_fin                     #The transcribed text is stored here\n",
    "userq = text_fin.get('text' , '')\n",
    "userq                                 #This userq will be fed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg                         #Importing ffmpeg to be able to manipulate the audio files\n",
    "ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "import google.generativeai as genai\n",
    "GOOGLE_API_KEY = \"PASTE YOUR API KEY HERE\"\n",
    "genai.configure(api_key = GOOGLE_API_KEY)    #The google api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "title_template = PromptTemplate(               #prompt template for the chatbot\n",
    "    input_variables = ['topic'],\n",
    "    template = \"You're the VAB (Voice Assisted Bhuvan chatBot), A chatbot created by the team Turing Titans and you are a personal assistant and query resolver for the BHUVAN portal of geospatial data created for the purpose of helping users seamlessly and easily navigate across BHUVAN portal. While keeping this in mind, {topic}\"\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY, temperature = 0.5)   #llm being used for the chatbot\n",
    "vab_chain = LLMChain(llm=llm, prompt=title_template, verbose=True)      #llm chain, to get the chatbot response with the appropriate system prompt\n",
    "bot_response = vab_chain.run(topic = userq)                    #running the chain with the user input\n",
    "print(bot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "out = translator.translate(bot_response, dest='en')           #Translating the output to English\n",
    "print(out.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
